{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Privacy Final Project\n",
    "\n",
    "Jordan Bourdeau, Casey Forey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jorda\\AppData\\Local\\Temp\\ipykernel_25376\\3232557608.py:30: DtypeWarning: Columns (33,35,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df: pd.DataFrame = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe loaded\n"
     ]
    }
   ],
   "source": [
    "url: str = 'https://jbourde2.w3.uvm.edu/data-privacy/data.zip'\n",
    "file_path: str = 'data/powerlifting-data.csv'\n",
    "\n",
    "# If the .zip file doesn't already exist, download it from the Silk server.\n",
    "if not os.path.exists('data.zip'):\n",
    "    try:\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        print('Downloading zip file from server')\n",
    "        open('data.zip', 'wb').write(r.content)\n",
    "        print('Zip file downloaded from server')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('Unable to download zip file from remote server')\n",
    "        exit(1)\n",
    "\n",
    "# If the data folder doesn't already exist, unzip the data zip\n",
    "if not os.path.exists('data/'):\n",
    "    try:\n",
    "        with zipfile.ZipFile('data.zip') as zip:\n",
    "            zip.extractall()\n",
    "        print('Zip file extracted')\n",
    "        df = pd.read_csv(file_path)\n",
    "        print('Data read in')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('No zip file to extract from')\n",
    "        exit(1)\n",
    "\n",
    "print('Loading dataframe')\n",
    "df: pd.DataFrame = pd.read_csv(file_path)\n",
    "# Drop unneeded columns\n",
    "df = df.drop(['BirthYearClass', 'Division', 'AgeClass', 'Dots', 'Wilks', 'Glossbrenner', 'Goodlift', \n",
    "                'Federation', 'MeetCountry', 'MeetState', 'MeetTown', 'WeightClassKg',\n",
    "                'Squat4Kg', 'Bench4Kg', 'Deadlift4Kg',], axis=1)\n",
    "print('Dataframe loaded')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Privacy Budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho: float = .1\n",
    "rho_i: float = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differential Privacy Mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_mech_zCDP_vec(vec, sensitivity, rho):\n",
    "    sigma = np.sqrt((sensitivity**2) / (2 * rho))\n",
    "    return [v + np.random.normal(loc=0, scale=sigma) for v in vec]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit of privacy conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As is, the unit of privacy is person-meet-division-age division\n",
    "\n",
    "# 1. Remove all records which are not from a full-power division\n",
    "# Drop any rows with NaN values in it.\n",
    "# Fill NaN tested rows first\n",
    "df['Tested'] = df['Tested'].fillna(0)\n",
    "df = df[df['Event'] == 'SBD']\n",
    "df = df.dropna()\n",
    "\n",
    "# 2. Limit to 1 record per meet (based on meet name/date for a person)\n",
    "person_meet_columns: list[str] = ['Name', 'MeetName', 'Date']\n",
    "df = df.drop_duplicates(subset=person_meet_columns, keep='first')\n",
    "\n",
    "# 3. Convert person-meet unit of privacy to person-year\n",
    "# Note: Person-state would protect a person while they reside in a specific state.\n",
    "# Identifying in terms of how we determine a 'unique' person, all data can be identifying\n",
    "# Full name + sex + competes in powerlifting is incredibly identifying so this is a proxy for a 'person'\n",
    "df['Year'] = df['Date'].map(lambda x: int(x[:4]))\n",
    "identifying_columns: list[str] = ['Name', 'Sex']\n",
    "histogram = df.groupby(identifying_columns).size()\n",
    "noisy_histogram = gaussian_mech_zCDP_vec(histogram, 1, rho/2)\n",
    "df = df.drop(['Name'], axis=1)\n",
    "\n",
    "# This is our scalar value to divide rho by (max number of times a person has competed in a given year)\n",
    "noisy_max: float = np.max(noisy_histogram)\n",
    "rho_i = rho / (2 * noisy_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert sex and tested columns into binary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Mx columns for a simplifying assumption\n",
    "df = df[df['Sex'] != 'Mx']\n",
    "\n",
    "# Convert binary categorical columns into binary values\n",
    "sex: dict = {'M': 1,'F': 0}\n",
    "df['Tested'] = df['Tested'].map(lambda x: 1 if x == 'Yes' else x)\n",
    "df['Sex'] = df['Sex'].map(sex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert attempts into attempt weight and success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If an attempt was missed, it has a '-' put in front of it\n",
    "# Separate each attempt into the weight loaded and whether it was successful.\n",
    "attempt_columns: list[str] = ['Squat1Kg', 'Squat2Kg', 'Squat3Kg',\n",
    "                              'Bench1Kg', 'Bench2Kg', 'Bench3Kg',\n",
    "                              'Deadlift1Kg', 'Deadlift2Kg', 'Deadlift3Kg']\n",
    "\n",
    "for column in attempt_columns:\n",
    "    df[f\"{column}Made\"] = df[column].map(lambda x: 1 if x > 0 else 0)\n",
    "    df[column] = np.abs(df[column])\n",
    "\n",
    "best_attempt_columns: list[str] = ['Best3SquatKg', 'Best3BenchKg', 'Best3DeadliftKg']\n",
    "\n",
    "# If someone didn't hit any lifts, convert their best 3rd to 0\n",
    "for column in best_attempt_columns:\n",
    "    df[column] = df[column].map(lambda x: x if x > 0 else 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create One-Hot-Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-hot encodings if they don't exist\n",
    "categorical_columns: list[str] = ['Equipment', 'ParentFederation']\n",
    "if 'encoded_features' not in locals():\n",
    "    # Create the One-Hot-Encoding\n",
    "    encoded_features: list[pd.DataFrame] = [df[column].str.get_dummies(\"|\") for column in categorical_columns if column in df.columns]\n",
    "\n",
    "# Drop the categorical columns if they are in the dataframe\n",
    "df = df.drop(categorical_columns, axis=1, errors='ignore')\n",
    "\n",
    "# Concatenate one-hot-encoded columns along the column axis\n",
    "for features in encoded_features:\n",
    "    for column in features.columns:\n",
    "        df[column] = features[column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop the remaining unneeded columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Machine learning functions (loss, gradient, noisy gradient descent).\n",
    "'''\n",
    "\n",
    "# The loss function measures how good our model is. The training goal is to minimize the loss.\n",
    "# This is the logistic loss function.\n",
    "def loss(theta, xi, yi):\n",
    "    exponent = - yi * (xi.dot(theta))\n",
    "    return np.log(1 + np.exp(exponent))\n",
    "\n",
    "# This is the gradient of the logistic loss\n",
    "# The gradient is a vector that indicates the rate of change of the loss in each direction\n",
    "def gradient(theta, xi, yi):\n",
    "    exponent = yi * (xi.dot(theta))\n",
    "    return - (yi*xi) / (1+np.exp(exponent))\n",
    "\n",
    "def avg_grad(theta, X, y):\n",
    "    grads = [gradient(theta, xi, yi) for xi, yi in zip(X, y)]\n",
    "    return np.mean(grads, axis=0)\n",
    "\n",
    "# Prediction: take a model (theta) and a single example (xi) and return its predicted label\n",
    "def predict(xi, theta, bias=0):\n",
    "    label = np.sign(xi @ theta + bias)\n",
    "    return label\n",
    "\n",
    "def accuracy(theta, X_test, y_test):\n",
    "    return np.sum(predict(X_test, theta) == y_test) / X_test.shape[0]\n",
    "\n",
    "# L2 Clipping\n",
    "def L2_clip(v, b):\n",
    "    norm = np.linalg.norm(v, ord=2)\n",
    "    if norm > b:\n",
    "        return b * (v / norm)\n",
    "    else:\n",
    "        return v\n",
    "\n",
    "def gradient_sum(theta, X, y, b):\n",
    "    gradients = [L2_clip(gradient(theta, x_i, y_i), b) for x_i, y_i in zip(X,y)]\n",
    "    # sum query\n",
    "    # L2 sensitivity is b (by clipping performed above)\n",
    "    return np.sum(gradients, axis=0)\n",
    "\n",
    "def noisy_gradient_descent_zCDP(X_train, y_train, iterations, rho, learning_rate):\n",
    "    theta = np.zeros(X_train.shape[1])\n",
    "    b = 3\n",
    "    rho_count = 0.05 * rho\n",
    "    rho_i = 0.95 * rho / iterations\n",
    "    noisy_count = gaussian_mech_zCDP_vec([X_train.shape[0]], 1, rho_count)[0]\n",
    "    for i in range(iterations):\n",
    "        clipped_gradient_sum = gradient_sum(theta, X_train, y_train, b)\n",
    "        noisy_gradient_sum = np.array(gaussian_mech_zCDP_vec(clipped_gradient_sum, b, rho_i))\n",
    "        noisy_avg_gradient = noisy_gradient_sum / noisy_count\n",
    "        theta = theta - noisy_avg_gradient * learning_rate\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations: int = 10\n",
    "learning_rate: float = 0.5\n",
    "num_models: int = 2\n",
    "rho_i /= num_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can we predict whether someone is competing in a tested vs. untested meet based on their best lifts and weight?\n",
      "Percentage of tested meets: 0.7783904382470119%\n",
      "Scikit-learn reference:\n",
      "0.8090571049136787\n",
      "Noisy gradient descent:\n",
      "[ 6.61791956e-01  4.15798002e-01  7.77334499e-01  3.55450222e-01\n",
      "  3.07844850e-04  6.53335220e-03 -1.00171798e-03 -2.07385725e-03\n",
      "  2.31337896e-04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jorda\\AppData\\Local\\Temp\\ipykernel_25376\\2833084511.py:15: RuntimeWarning: overflow encountered in exp\n",
      "  return - (yi*xi) / (1+np.exp(exponent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.62046836e-01  4.16154462e-01  7.77462099e-01  3.56424217e-01\n",
      " -3.14478139e-04  6.18896207e-03 -5.65315130e-04 -2.99337515e-03\n",
      "  1.37414558e-03]\n",
      "[ 6.62559370e-01  4.16799735e-01  7.77597157e-01  3.55853992e-01\n",
      " -1.34200619e-03  6.83455068e-03 -9.96942650e-04 -3.90752970e-03\n",
      "  3.19677147e-04]\n",
      "[ 6.63029732e-01  4.16314949e-01  7.78469485e-01  3.56454563e-01\n",
      " -3.06406318e-03  6.84780229e-03 -2.35752933e-03 -4.25213433e-03\n",
      "  6.78630111e-04]\n",
      "[ 0.66201391  0.41700341  0.77737445  0.35677388 -0.00220474  0.00676722\n",
      " -0.00180471 -0.00343471 -0.00143735]\n",
      "[ 0.66279608  0.41684828  0.77696351  0.35504606 -0.00264449  0.00679137\n",
      " -0.00262708 -0.00385447 -0.00112793]\n",
      "[ 6.63689210e-01  4.14348062e-01  7.76037506e-01  3.54838585e-01\n",
      " -1.57524424e-03  6.05130299e-03 -1.38053453e-03 -3.59108244e-03\n",
      " -3.11195480e-04]\n",
      "[ 6.63204307e-01  4.15408425e-01  7.77042137e-01  3.53335774e-01\n",
      " -1.93144569e-03  5.90909823e-03 -2.56163538e-04 -5.91368987e-03\n",
      "  3.46395601e-04]\n",
      "[ 0.66472008  0.41510437  0.77616844  0.35174169 -0.00211416  0.00691709\n",
      "  0.00218411 -0.0075574   0.00117681]\n",
      "[ 0.66527201  0.41539732  0.77664332  0.35224206 -0.00288614  0.00648475\n",
      "  0.00093861 -0.00641788  0.00213451]\n",
      "0.7806108897742364\n"
     ]
    }
   ],
   "source": [
    "print(\"Can we predict whether someone is competing in a tested vs. untested meet based on their best lifts and weight?\")\n",
    "y = df['Tested'].values\n",
    "X = df[['Best3SquatKg', 'Best3BenchKg', 'Best3DeadliftKg', 'BodyweightKg', 'Multi-ply', 'Raw', 'Single-ply', 'Unlimited', 'Wraps']].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, test_size=0.20, random_state=42)\n",
    "\n",
    "print(f\"Percentage of tested meets: \\n{len(df[df['Tested'] == 1]) / len(df):.3f}%\")\n",
    "\n",
    "print(\"Scikit-learn reference:\")\n",
    "model: LogisticRegression = LogisticRegression().fit(X_train, y_train)\n",
    "print(np.sum(model.predict(X_test) == y_test) / X_test.shape[0])\n",
    "\n",
    "print(\"Noisy gradient descent:\")\n",
    "theta = noisy_gradient_descent_zCDP(X_train, y_train, iterations, rho_i, learning_rate)\n",
    "print(accuracy(theta, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can we predict whether someone will hit their 3rd deadlift based on their previous lifts and other metrics?\n",
      "Percentage of people who made their third deadlifts: 0.643%\n",
      "Scikit-learn reference:\n",
      "0.6616998671978752\n",
      "Noisy gradient descent:\n",
      "0.6404249667994688\n"
     ]
    }
   ],
   "source": [
    "print(\"Can we predict whether someone will hit their 3rd deadlift based on their previous lifts and other metrics?\")\n",
    "predictive_columns: list[str] = ['Squat1KgMade', 'Squat2KgMade', 'Squat3KgMade', \n",
    "                                'Bench1KgMade', 'Bench2KgMade', 'Bench3KgMade', \n",
    "                                'Deadlift1KgMade', 'Deadlift2KgMade']\n",
    "y = df['Deadlift3KgMade'].values\n",
    "X = df[predictive_columns].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.80, test_size=0.20, random_state=42)\n",
    "\n",
    "print(f\"Percentage of people who made their third deadlifts: \\n{len(df[df['Deadlift3KgMade'] == 1]) / len(df):.3f}%\")\n",
    "\n",
    "print(\"Scikit-learn reference:\")\n",
    "model: LogisticRegression = LogisticRegression().fit(X_train, y_train)\n",
    "print(np.sum(model.predict(X_test) == y_test) / X_test.shape[0])\n",
    "\n",
    "print(\"Noisy gradient descent:\")\n",
    "theta = noisy_gradient_descent_zCDP(X_train, y_train, iterations, rho_i, learning_rate)\n",
    "print(accuracy(theta, X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
